
judge_method: ranking

prompts:
  ranking: ranking_prompts.txt
  # scores:
    # - scores_ranking.txt
eval_dataset:
  - "tatsu-lab/alpaca_eval"
  - "alpaca_eval"